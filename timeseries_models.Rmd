---
title: "Timeseries models"
runtime: shiny
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
```

## Discrete White Noise

If the elements of the series, $w_i$ , are independent and identically distributed (i.i.d.),
with a mean of zero, variance $σ^2$  and no serial correlation (i.e. $Cor(w_i , w_j ) = 0, ∀i \neq j$)
then we say that the time series is discrete white noise (DWN).


## Random Walk

A random walk is a time series model $x_t$ such that $x_t = x_{t−1} + w_t$ , where $w_t$ is a discrete white noise series.
Random walks are non-stationary, and variance is time-dependent.

```{r}
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
for (t in 2:1000) x[t] <- x[t-1] + w[t]
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


# Autoregressive models (AR(p))

  
  
$$x_t = α_1 x_{t−1} + . . . + α_p x_{t−p} + w_t$$

$$θ_p(\mathbf{B})x_t = (1 − α_1 \mathbf{B} − α_2 \mathbf{B}^2 − . . . − α_p \mathbf{B}^p)x_t = w_t$$


Characteristic equation: $$θ_p (\mathbf{B}) = 0$$

AR(p) is stationary only if all roots exceed 1!

Examples

- Random Walk = AR(1) process with $α_1 = 1$: $θ = 1−B$ =>$B=1$ => not stationary
- AR(1) with $a_1 = 1/4$ => $B = 4$ => stationary
- AR(2) with $α_1 = α_2 = 2$ => $B = 1, B= −2$ => not stationary 


## AR(1)

### AR(1), a1 = 0.6

```{r}
a1 = 0.6
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <-w[1]
for (t in 2:1000) x[t] <- a1 * x[t-1] + w[t]
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


### AR(1), a1 = 0.1

```{r}
a1 = 0.1
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
for (t in 2:1000) x[t] <- a1 * x[t-1] + w[t]
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


## AR(2)

```{r}
a1 = 0.6
a2 = 0.3
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
x[2] <- w[2]
for (t in 3:1000) x[t] <- a1 * x[t-1] + a2 * x[t-2] + w[t]
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```

## AR(3)

```{r}
a1 = 0.06
a2 = 0.03
a3 = -0.4
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
x[2] <- w[2]
x[3] <- w[3] 
for (t in 4:1000) x[t] <- a1 * x[t-1] + a2 * x[t-2] + a3 * x[t-3] + w[t]
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


# Moving average models (MA(q))

  

$$x_t = w_t + \beta_1 w_{t−1} + . . . + \beta_q w_{t−q}$$

$$\phi_q(\mathbf{B})w_t = (1 + \beta_1 \mathbf{B} + \beta_2 \mathbf{B}^2 + . . . + \beta_q \mathbf{B}^q)w_t = x_t$$

## MA(1)

```{r}
b1 = 0.6
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
for (t in 2:1000) x[t] <-  w[t] + b1 * w[t-1] 
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```

```{r}
b1 = 0.1
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
for (t in 2:1000) x[t] <-  w[t] + b1 * w[t-1] 
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


## MA(2)

```{r}
b1 = 0.6
b2 = 0.3
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
x[2] <- w[2]
for (t in 3:1000) x[t] <-  w[t] + b1 * w[t-1] + b2 * w[t-2] 
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


# ARMA(p,q)

```{r}
x <- arima.sim(n=1000, model=list(ar=0.5, ma=-0.5))
plot(x)
acf(x)
pacf(x)
auto.arima(x)
```


# ARIMA(p,d,q)

```{r}
x <- arima.sim(list(order = c(1,1,1), ar = 0.6, ma=-0.5), n = 1000)
plot(x)
acf(x)
pacf(x)
auto.arima(x)
```

```{r}
x <- arima.sim(list(order = c(2,2,0), ar = c(0.6,-0.5)), n = 1000)
plot(x)
acf(x)
pacf(x)
auto.arima(x)
```


# Generalised Autoregressive Conditional Heteroskedastic Models (GARCH(p,q))

Time series values:

$$\epsilon_t = \sigma_t w_t$$


Variance:

$$\sigma^2_t = \alpha_0 + \sum_{i=1}^{q} \alpha_i \epsilon_{t-i}^2 + \sum_{j=1}^{p} \beta_j \sigma_{t-j}^2$$


```{r}
set.seed(777)
a0 <- 0.2
a1 <- 0.5
b1 <- 0.3
w <- rnorm(10000)
eps <- rep(NA, 10000)
sigsq <- rep(NA, 10000)
for (i in 2:10000) {
sigsq[i] <- a0 + a1 * (eps[i-1]^2) + b1 * sigsq[i-1]
eps[i] <- w[i]*sqrt(sigsq[i])}
```