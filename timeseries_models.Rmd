---
title: "Timeseries models"
runtime: shiny
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(tseries)
```


## Discrete White Noise

If the elements of the series, $w_i$ , are independent and identically distributed (i.i.d.),
with a mean of zero, variance $σ^2$  and no serial correlation (i.e. $Cor(w_i , w_j ) = 0, ∀i \neq j$)
then we say that the time series is discrete white noise (DWN).


## Random Walk

A random walk is a time series model $x_t$ such that $x_t = x_{t−1} + w_t$ , where $w_t$ is a discrete white noise series.
Random walks are non-stationary, and variance is time-dependent.

```{r}
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
for (t in 2:1000) x[t] <- x[t-1] + w[t]
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


# Autoregressive models (AR(p))

  
  
$$x_t = α_1 x_{t−1} + . . . + α_p x_{t−p} + w_t$$

$$θ_p(\mathbf{B})x_t = (1 − α_1 \mathbf{B} − α_2 \mathbf{B}^2 − . . . − α_p \mathbf{B}^p)x_t = w_t$$


Characteristic equation: $$θ_p (\mathbf{B}) = 0$$

AR(p) is stationary only if all roots exceed 1!

Examples

- Random Walk = AR(1) process with $α_1 = 1$: $θ = 1−B$ =>$B=1$ => not stationary
- AR(1) with $a_1 = 1/4$ => $B = 4$ => stationary
- AR(2) with $α_1 = α_2 = 2$ => $B = 1, B= −2$ => not stationary 


## AR(1)

### AR(1), a1 = 0.6

```{r}
a1 = 0.6
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <-w[1]
for (t in 2:1000) x[t] <- a1 * x[t-1] + w[t]
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


### AR(1), a1 = 0.1

```{r}
a1 = 0.1
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
for (t in 2:1000) x[t] <- a1 * x[t-1] + w[t]
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


## AR(2)

```{r}
a1 = 0.6
a2 = 0.3
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
x[2] <- w[2]
for (t in 3:1000) x[t] <- a1 * x[t-1] + a2 * x[t-2] + w[t]
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```

## AR(3)

```{r}
a1 = 0.06
a2 = 0.03
a3 = -0.4
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
x[2] <- w[2]
x[3] <- w[3] 
for (t in 4:1000) x[t] <- a1 * x[t-1] + a2 * x[t-2] + a3 * x[t-3] + w[t]
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


# Moving average models (MA(q))

  

$$x_t = w_t + \beta_1 w_{t−1} + . . . + \beta_q w_{t−q}$$

$$\phi_q(\mathbf{B})w_t = (1 + \beta_1 \mathbf{B} + \beta_2 \mathbf{B}^2 + . . . + \beta_q \mathbf{B}^q)w_t = x_t$$

## MA(1)

```{r}
b1 = 0.6
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
for (t in 2:1000) x[t] <-  w[t] + b1 * w[t-1] 
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```

```{r}
b1 = 0.1
set.seed(777)
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
for (t in 2:1000) x[t] <-  w[t] + b1 * w[t-1] 
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


## MA(2)

```{r}
b1 = 0.6
b2 = 0.3
x <- rep(NA, 1000)
w <- rnorm(1000)
x[1] <- w[1]
x[2] <- w[2]
for (t in 3:1000) x[t] <-  w[t] + b1 * w[t-1] + b2 * w[t-2] 
plot(x, type="l")
acf(x)
pacf(x)
auto.arima(x)
```


# ARMA(p,q)

```{r}
x <- arima.sim(n=1000, model=list(ar=0.5, ma=-0.5))
plot(x)
acf(x)
pacf(x)
auto.arima(x)
```


# ARIMA(p,d,q)

```{r}
x <- arima.sim(list(order = c(1,1,1), ar = 0.6, ma=-0.5), n = 1000)
plot(x)
acf(x)
pacf(x)
auto.arima(x)
```

```{r}
x <- arima.sim(list(order = c(2,2,0), ar = c(0.6,-0.5)), n = 1000)
plot(x)
acf(x)
pacf(x)
auto.arima(x)
```


# Generalised Autoregressive Conditional Heteroskedastic Models (GARCH(p,q))

Time series values:

$$\epsilon_t = \sigma_t w_t$$


Variance:

$$\sigma^2_t = \alpha_0 + \sum_{i=1}^{q} \alpha_i \epsilon_{t-i}^2 + \sum_{j=1}^{p} \beta_j \sigma_{t-j}^2$$


```{r}
#create the data
# set.seed(777) does not converge
set.seed(2)
a0 <- 0.2
a1 <- 0.5
b1 <- 0.3
w <- rnorm(10000)
eps <- rep(NA, 10000)
eps[1] <- 0
sigsq <- rep(NA, 10000)
sigsq[1] <- 0
for (i in 2:10000) {
  sigsq[i] <- a0 + a1 * (eps[i-1]^2) + b1 * sigsq[i-1]
  eps[i] <- w[i]*sqrt(sigsq[i])
}

# does the series look like white noise? 
acf(eps)
#  does the series squared look like white noise? 
acf(eps^2)

fit <- garch(eps)
summary(fit)
confint(fit)
```


## ARIMA and GARCH residuals compared

```{r}
#create the data
# set.seed(777) does not converge
set.seed(2)
a0 <- 0.2
a1 <- 0.5
b1 <- 0.3
w <- rnorm(10000)
eps <- rep(NA, 10000)
eps[1] <- 0
sigsq <- rep(NA, 10000)
sigsq[1] <- 0
for (i in 2:10000) {
  sigsq[i] <- a0 + a1 * (eps[i-1]^2) + b1 * sigsq[i-1]
  eps[i] <- w[i]*sqrt(sigsq[i])
}

# ARIMA
fit1 <- auto.arima(eps)
summary(fit1)
# do the residuals look like white noise? 
acf(resid(fit1))
#  do the squared residuals look like white noise?
acf(resid(fit1)^2)

# GARCH
fit2 <- garch(eps)
summary(fit2)
# do the residuals look like white noise? 
acf(resid(fit2)[-1])
#  do the squared residuals look like white noise?
acf((resid(fit2)^2)[-1])
```


## ARIMA and GARCH using rugarch

```{r}
library(rugarch)

#create the data
# set.seed(777) does not converge
set.seed(2)
a0 <- 0.2
a1 <- 0.5
b1 <- 0.3
w <- rnorm(10000)
eps <- rep(NA, 10000)
eps[1] <- 0
sigsq <- rep(NA, 10000)
sigsq[1] <- 0
for (i in 2:10000) {
  sigsq[i] <- a0 + a1 * (eps[i-1]^2) + b1 * sigsq[i-1]
  eps[i] <- w[i]*sqrt(sigsq[i])
}

# get arima order 
library(forecast)
fit1 <- auto.arima(eps)
o1 <- arimaorder(fit1)

# create spec for ugarch
spec = ugarchspec(
  variance.model=list(garchOrder=c(1,1)),
  mean.model=list(armaOrder=c(o1[1], o1[3]), include.mean=T),
  distribution.model="sged")
spec

# fit ugarch
fit2 = ugarchfit(spec, eps, solver = 'hybrid')
fit2
```


# Cointegration

## Using standard lm

```{r}
library("quantmod")

getSymbols("EWA", from="2006-04-26", to="2012-04-09")
getSymbols("EWC", from="2006-04-26", to="2012-04-09")

ewaAdj = unclass(EWA$EWA.Adjusted)
ewcAdj = unclass(EWC$EWC.Adjusted)

plot(ewaAdj, type="l", xlim=c(0, 1500), ylim=c(5.0, 35.0),
xlab="April 26th 2006 to April 9th 2012",
ylab="ETF Backward-Adjusted Price in USD", col="blue")
par(new=T)
plot(ewcAdj, type="l", xlim=c(0, 1500), ylim=c(5.0, 35.0),
axes=F, xlab="", ylab="", col="red")
par(new=F)
```